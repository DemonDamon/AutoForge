# AutoForge
ğŸ¤– AutoForge - åŸºäºHuggingFaceçš„å…¨è‡ªåŠ¨åŒ–æ¨¡å‹ä¼˜åŒ–æ¡†æ¶ã€‚è‡ªåŠ¨æœç´¢ã€è¯„ä¼°ã€å¾®è°ƒï¼Œç›´åˆ°æ‰¾åˆ°æœ€ä¼˜è§£å†³æ–¹æ¡ˆï¼ğŸš€

## ğŸ“– é¡¹ç›®ç®€ä»‹

AutoForge æ˜¯ä¸€ä¸ªæ™ºèƒ½åŒ–çš„æœºå™¨å­¦ä¹ æ¨¡å‹é€‰å‹å’Œä¼˜åŒ–æ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿï¼š

1. **ğŸ“‹ éœ€æ±‚åˆ†æ**ï¼šè‡ªåŠ¨è§£æå¤šæ¨¡æ€æ–‡æ¡£ï¼ˆPDF/Word/Excel/å›¾ç‰‡ç­‰ï¼‰ï¼Œç†è§£é¡¹ç›®éœ€æ±‚
2. **ğŸ” æ¨¡å‹æœç´¢**ï¼šåŸºäºéœ€æ±‚è‡ªåŠ¨åœ¨HuggingFaceä¸Šæœç´¢æœ€ä¼˜æ¨¡å‹
3. **ğŸ“Š æ–¹æ¡ˆè®¾è®¡**ï¼šè‡ªåŠ¨è®¾è®¡æ•°æ®é›†æ„å»ºæ–¹æ¡ˆå’Œç½‘æ ¼åŒ–å®éªŒæ–¹æ¡ˆ
4. **ğŸ¯ ç»“æœåˆ†æ**ï¼šåˆ†æå®éªŒç»“æœå¹¶ç»™å‡ºæœ€ç»ˆé€‰å‹å»ºè®®
5. **ğŸ”¬ è®ºæ–‡åˆ†æ**ï¼šä»Papers with Codeçˆ¬å–æœ€æ–°è®ºæ–‡å¹¶åˆ†æç›¸å…³GitHubä»“åº“

ğŸ“ é¡¹ç›®ç»“æ„
```
AutoForge/
â”œâ”€â”€ autoforge/              # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py            # ä¸»Agentç±»
â”‚   â”œâ”€â”€ analyzers/         # åˆ†æå™¨ç»„ä»¶
â”‚   â”œâ”€â”€ docparser/         # æ–‡æ¡£è§£æå™¨
â”‚   â”œâ”€â”€ llm/              # LLMå®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ openai_client.py  # OpenAIå®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ deepseek_client.py  # DeepSeekå®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ bailian_client.py   # ç™¾ç‚¼å®¢æˆ·ç«¯
â”‚   â”‚   â””â”€â”€ base.py            # åŸºç±»
â”‚   â”œâ”€â”€ crawler/          # çˆ¬è™«æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ hf_crawler.py      # HuggingFaceçˆ¬è™«
â”‚   â”‚   â”œâ”€â”€ pwc_crawler.py     # Papers with Codeçˆ¬è™«
â”‚   â”‚   â””â”€â”€ github_repo_analyzer.py  # GitHubä»“åº“åˆ†æ
â”‚   â””â”€â”€ prompts/          # æç¤ºè¯ç®¡ç†
â”œâ”€â”€ examples/              # ä½¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ quick_start.py     # å¿«é€Ÿå…¥é—¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ multi_llm_example.py  # å¤šLLMæä¾›å•†ç¤ºä¾‹
â”‚   â”œâ”€â”€ crawler_demo.py    # çˆ¬è™«åŠŸèƒ½ç¤ºä¾‹
â”‚   â”œâ”€â”€ pwc_github_analysis.py  # Papers with Codeå’ŒGitHubåˆ†æç¤ºä¾‹
â”‚   â””â”€â”€ search_models.py         # è§†é¢‘æ ‡é¢˜è§„èŒƒåŒ–ç¤ºä¾‹
â”œâ”€â”€ outputs/               # è¾“å‡ºç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”œâ”€â”€ requirements.txt       # é¡¹ç›®ä¾èµ–
â”œâ”€â”€ setup.py              # å®‰è£…é…ç½®
â”œâ”€â”€ config.example.py     # é…ç½®ç¤ºä¾‹
â””â”€â”€ README.md             # è¯¦ç»†æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/AutoForge.git
cd AutoForge

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½®LLM

AutoForgeæ”¯æŒå¤šç§LLMæä¾›å•†ï¼ŒåŒ…æ‹¬OpenAIã€DeepSeekå’Œé˜¿é‡Œäº‘ç™¾ç‚¼ï¼š

```bash
# OpenAIï¼ˆé»˜è®¤ï¼‰
export OPENAI_API_KEY="your-openai-api-key-here"

# DeepSeekï¼ˆå¯é€‰ï¼‰
export DEEPSEEK_API_KEY="your-deepseek-api-key-here"

# é˜¿é‡Œäº‘ç™¾ç‚¼ï¼ˆå¯é€‰ï¼‰
export DASHSCOPE_API_KEY="your-dashscope-api-key-here"
```

### 3. ç¤ºä¾‹ç¨‹åº

AutoForgeæä¾›äº†å‡ ä¸ªç¤ºä¾‹ç¨‹åºï¼Œç”¨äºå¿«é€Ÿä¸Šæ‰‹ï¼š

- **quick_start.py** - åŸºç¡€å…¥é—¨ç¤ºä¾‹
- **multi_llm_example.py** - å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„LLMæä¾›å•†
- **crawler_demo.py** - å±•ç¤ºHuggingFaceçˆ¬è™«åŠŸèƒ½
- **pwc_github_analysis.py** - å±•ç¤ºPapers with Codeå’ŒGitHubåˆ†æç¤ºä¾‹
- **search_models.py** - è§†é¢‘æ ‡é¢˜è§„èŒƒåŒ–å®é™…åº”ç”¨ç¤ºä¾‹

è¿è¡Œç¤ºä¾‹ï¼š
```bash
# å¿«é€Ÿå…¥é—¨ç¤ºä¾‹
python examples/quick_start.py

# å¤šLLMæä¾›å•†ç¤ºä¾‹
python examples/multi_llm_example.py

# çˆ¬è™«åŠŸèƒ½ç¤ºä¾‹
python examples/crawler_demo.py

# Papers with Codeå’ŒGitHubåˆ†æç¤ºä¾‹
python examples/pwc_github_analysis.py

# è§†é¢‘æ ‡é¢˜æ¸…æ´—ç®—æ³•ä»»åŠ¡ç¤ºä¾‹
python examples/search_models.py
```

## ğŸ“š è¯¦ç»†ä½¿ç”¨æŒ‡å—

### 1. éœ€æ±‚è¾“å…¥æ–¹å¼

AutoForgeæ”¯æŒå¤šç§éœ€æ±‚è¾“å…¥æ–¹å¼ï¼š

#### a) æ‰‹åŠ¨è¾“å…¥æè¿°
```python
agent.analyze_requirements(
    manual_description="ä½ çš„éœ€æ±‚æè¿°..."
)
```

#### b) è§£æå•ä¸ªæ–‡æ¡£
```python
agent.analyze_requirements(
    document_path="path/to/requirement.pdf"
)
```

#### c) è§£ææ–‡æ¡£ç›®å½•
```python
agent.analyze_requirements(
    document_path="path/to/documents/"
)
```

### 2. åˆ†æ­¥æ‰§è¡Œæµç¨‹

ä½ å¯ä»¥åˆ†æ­¥æ‰§è¡Œå„ä¸ªé˜¶æ®µï¼š

```python
# æ­¥éª¤1: éœ€æ±‚åˆ†æ
requirement_result = agent.analyze_requirements(...)

# æ­¥éª¤2: æ¨¡å‹æœç´¢
model_result = agent.search_models()

# æ­¥éª¤3.1: æ•°æ®é›†è®¾è®¡
dataset_result = agent.design_dataset()

# æ­¥éª¤3.2: å®éªŒè®¾è®¡
experiment_result = agent.design_experiments()

# æ­¥éª¤3.3: ç»“æœåˆ†æï¼ˆéœ€è¦å®éªŒæŠ¥å‘Šï¼‰
final_result = agent.analyze_results(
    experiment_reports=[...],
    hardware_info={...}
)
```

### 3. è¾“å‡ºç»“æœ

æ‰€æœ‰åˆ†æç»“æœéƒ½ä¼šä¿å­˜ä¸ºMarkdownæ–‡æ¡£ï¼Œä¾¿äºæŸ¥çœ‹å’Œåˆ†äº«ï¼š

```
outputs/
â”œâ”€â”€ requirement_analysis/      # éœ€æ±‚åˆ†æç»“æœ
â”œâ”€â”€ model_search/             # æ¨¡å‹æœç´¢ç»“æœ
â”œâ”€â”€ dataset_design/           # æ•°æ®é›†è®¾è®¡æ–¹æ¡ˆ
â”œâ”€â”€ experiment_design/        # å®éªŒè®¾è®¡æ–¹æ¡ˆ
â”œâ”€â”€ result_analysis/          # æœ€ç»ˆåˆ†æç»“æœ
â””â”€â”€ autoforge_final_report.md # æ±‡æ€»æŠ¥å‘Š
```

### 4. å¤šç§LLMæä¾›å•†æ”¯æŒ ğŸ†•

AutoForgeç°åœ¨æ”¯æŒå¤šç§LLMæä¾›å•†ï¼Œå¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ä½¿ç”¨ï¼š

#### a) OpenAIï¼ˆé»˜è®¤ï¼‰
```python
from autoforge.llm import OpenAIClient

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
openai_client = OpenAIClient(
    api_key="your-api-key-here",  # æˆ–ä»ç¯å¢ƒå˜é‡OPENAI_API_KEYè¯»å–
    model="gpt-4",
    base_url=None  # é»˜è®¤ä½¿ç”¨å®˜æ–¹APIç«¯ç‚¹
)

# åˆ›å»ºAgent
agent = AutoForgeAgent(llm_client=openai_client)
```

#### b) DeepSeek
```python
from autoforge.llm import DeepSeekClient

# åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
deepseek_client = DeepSeekClient(
    api_key="your-api-key-here",  # æˆ–ä»ç¯å¢ƒå˜é‡DEEPSEEK_API_KEYè¯»å–
    model="deepseek-chat",  # æˆ–ä½¿ç”¨ "deepseek-reasoner"
    base_url="https://api.deepseek.com"
)

# åˆ›å»ºAgent
agent = AutoForgeAgent(llm_client=deepseek_client)
```

#### c) é˜¿é‡Œäº‘ç™¾ç‚¼
```python
from autoforge.llm import BaiLianClient

# åˆå§‹åŒ–ç™¾ç‚¼å®¢æˆ·ç«¯
bailian_client = BaiLianClient(
    api_key="your-api-key-here",  # æˆ–ä»ç¯å¢ƒå˜é‡DASHSCOPE_API_KEYè¯»å–
    model="qwen-plus",  # ç™¾ç‚¼æ”¯æŒçš„æ¨¡å‹ï¼Œå¦‚qwen-plus
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# åˆ›å»ºAgent
agent = AutoForgeAgent(llm_client=bailian_client)
```

#### d) ä½¿ç”¨é…ç½®æ–‡ä»¶
```python
# ä»config.custom.pyåŠ è½½é…ç½®
agent = AutoForgeAgent(
    llm_config={
        "provider": "deepseek",  # æˆ– "openai"ã€"bailian"
        "api_key": "your-api-key-here",
        "model": "deepseek-chat",
        "base_url": "https://api.deepseek.com"
    }
)
```

### 5. HuggingFaceçˆ¬è™«ä½¿ç”¨

```python
from autoforge.crawler import HuggingFaceCrawler

# åˆ›å»ºçˆ¬è™«å®ä¾‹
crawler = HuggingFaceCrawler(
    base_url="https://hf-mirror.com",  # å¯ä»¥ä½¿ç”¨é•œåƒç«™
    output_dir="outputs/hf_models",
    max_workers=4,  # å¹¶å‘çº¿ç¨‹æ•°
    delay=1.0       # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
)

# çˆ¬å–æ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„çƒ­é—¨æ¨¡å‹
models = crawler.crawl_models_by_task(
    task_tag="text-classification",
    sort="trending",  # æ’åºæ–¹å¼: trending/downloads/likes
    top_k=10          # çˆ¬å–å‰10ä¸ªæ¨¡å‹
)

# çˆ¬å–ç‰¹å®šæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
model_info = crawler.crawl_model_card("bert-base-chinese")

# æ‰¹é‡çˆ¬å–ï¼ˆåŒ…æ‹¬ModelCardï¼‰
detailed_models = crawler.crawl_models_batch(
    task_tag="text-classification",
    sort="downloads",
    top_k=5,
    fetch_details=True  # åŒæ—¶è·å–è¯¦ç»†ä¿¡æ¯
)
```

### 6. Papers with Codeçˆ¬è™«ä½¿ç”¨

```python
from autoforge.crawler import PwCCrawler

# åˆ›å»ºçˆ¬è™«å®ä¾‹
crawler = PwCCrawler(
    output_dir="outputs/papers",
    max_workers=4,  # å¹¶å‘çº¿ç¨‹æ•°
    delay=1.0       # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
)

# çˆ¬å–çƒ­é—¨è®ºæ–‡
papers = crawler.get_trending_papers(top_k=10)

# æŒ‰é¢†åŸŸçˆ¬å–è®ºæ–‡
papers = crawler.get_papers_by_field("Computer Vision", top_k=5)

# æœç´¢ç‰¹å®šè®ºæ–‡
papers = crawler.search_papers("transformer", top_k=5)

# è·å–è®ºæ–‡ç›¸å…³çš„GitHubä»“åº“
for paper in papers:
    github_repos = crawler.extract_github_links(paper["url"])
    print(f"è®ºæ–‡: {paper['title']} - ç›¸å…³ä»“åº“: {len(github_repos)}")
```

### 7. GitHubä»“åº“åˆ†æä½¿ç”¨

```python
from autoforge.crawler import GitHubRepoAnalyzer

# åˆ›å»ºåˆ†æå™¨å®ä¾‹
analyzer = GitHubRepoAnalyzer(
    output_dir="outputs/repos",
    clone_dir="temp_repos"
)

# åˆ†æå•ä¸ªä»“åº“
repo_info = analyzer.analyze_repo("https://github.com/username/repo")

# æŸ¥çœ‹è¯­è¨€ç»Ÿè®¡
print(f"ä»“åº“ä¸»è¦è¯­è¨€: {repo_info['languages']}")

# æŸ¥çœ‹ä¾èµ–å…³ç³»
print(f"Pythonä¾èµ–: {repo_info['dependencies'].get('python', [])}")

# æŸ¥çœ‹æ–‡ä»¶ç»“æ„
print(f"å…³é”®æ–‡ä»¶: {repo_info['key_files']}")

# æ¸…ç†å…‹éš†çš„ä»“åº“
analyzer.cleanup()
```

### 8. å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

```python
from autoforge.crawler import PwCCrawler, GitHubRepoAnalyzer

# ç¬¬1æ­¥: çˆ¬å–Papers with Codeä¸Šçš„è®ºæ–‡
pwc_crawler = PwCCrawler()
papers = pwc_crawler.search_papers("text classification", top_k=3)

# ç¬¬2æ­¥: æå–GitHubä»“åº“é“¾æ¥
github_links = []
for paper in papers:
    links = pwc_crawler.extract_github_links(paper["url"])
    github_links.extend(links)

# ç¬¬3æ­¥: åˆ†æGitHubä»“åº“
analyzer = GitHubRepoAnalyzer()
repo_analysis = []
for link in github_links:
    try:
        repo_info = analyzer.analyze_repo(link)
        repo_analysis.append(repo_info)
    except Exception as e:
        print(f"åˆ†æä»“åº“ {link} æ—¶å‡ºé”™: {e}")

# ç¬¬4æ­¥: ç”Ÿæˆåˆ†ææŠ¥å‘Š
for i, repo in enumerate(repo_analysis):
    print(f"\nä»“åº“ {i+1}: {repo['name']}")
    print(f"è¯­è¨€: {repo['languages']}")
    print(f"æ–‡ä»¶æ•°: {repo['file_count']}")
    print(f"ä¾èµ–: {', '.join(repo['dependencies'].get('python', []))}")
```

### 9. é›†æˆçˆ¬è™«çš„æ¨¡å‹æœç´¢

```python
# ModelSearcherä¼šè‡ªåŠ¨ä½¿ç”¨çˆ¬è™«è·å–æœ€æ–°æ¨¡å‹ä¿¡æ¯
agent = AutoForgeAgent(llm_client=llm_client)

# æ‰§è¡Œæ¨¡å‹æœç´¢æ—¶ä¼šè‡ªåŠ¨çˆ¬å–ç›¸å…³æ¨¡å‹
result = agent.search_models()

# æŸ¥çœ‹çˆ¬å–çš„æ¨¡å‹
if result.get('crawled_models'):
    print(f"çˆ¬å–åˆ° {len(result['crawled_models'])} ä¸ªæ¨¡å‹")
```

## ğŸ› ï¸ é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰æç¤ºè¯

åˆ›å»ºè‡ªå®šä¹‰æç¤ºè¯ç›®å½•ï¼š

```python
agent = AutoForgeAgent(
    llm_client=llm_client,
    custom_prompts_dir="path/to/prompts"
)
```

### 2. å®ç°è‡ªå®šä¹‰LLMå®¢æˆ·ç«¯

```python
from autoforge.llm import BaseLLMClient

class MyLLMClient(BaseLLMClient):
    def generate(self, prompt, **kwargs):
        # å®ç°ä½ çš„ç”Ÿæˆé€»è¾‘
        pass
        
    def generate_with_messages(self, messages, **kwargs):
        # å®ç°æ¶ˆæ¯æ ¼å¼çš„ç”Ÿæˆé€»è¾‘
        pass
```

### 3. æ–‡æ¡£è§£æå™¨é…ç½®

```python
from autoforge.docparser import MultiModalDocParser

parser = MultiModalDocParser(
    use_multimodal=True,  # ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹åˆ†æå›¾ç‰‡
    max_workers=8         # å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°
)
```

### 4. è®ºæ–‡å’Œä»£ç åˆ†ææµç¨‹

AutoForgeç°åœ¨æ”¯æŒä»å­¦æœ¯è®ºæ–‡åˆ°ä»£ç å®ç°çš„å®Œæ•´åˆ†ææµç¨‹ï¼š

```python
from autoforge.crawler import PwCCrawler, GitHubRepoAnalyzer

# åˆå§‹åŒ–ç»„ä»¶
pwc_crawler = PwCCrawler()
repo_analyzer = GitHubRepoAnalyzer()

# æœç´¢æœ€æ–°è®ºæ–‡
papers = pwc_crawler.search_papers("large language model", top_k=5)

# åˆ†æè®ºæ–‡ç›¸å…³ä»“åº“
for paper in papers:
    # æå–GitHubé“¾æ¥
    github_links = pwc_crawler.extract_github_links(paper["url"])
    
    # åˆ†ææ¯ä¸ªä»“åº“
    for link in github_links:
        repo_info = repo_analyzer.analyze_repo(link)
        
        # æå–æ¨¡å‹å®ç°ç»†èŠ‚
        if "model" in repo_info["key_files"]:
            print(f"å‘ç°æ¨¡å‹å®ç°: {repo_info['key_files']['model']}")
            
        # åˆ†æä¾èµ–å…³ç³»
        print(f"ä¾èµ–å…³ç³»: {repo_info['dependencies']}")
```

## ğŸ“‹ æ ¸å¿ƒç»„ä»¶

### 1. æ–‡æ¡£è§£æå™¨ (DocParser)
- æ”¯æŒæ ¼å¼ï¼šPDF, Word, Excel, CSV, å›¾ç‰‡, Markdown
- å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
- è‡ªåŠ¨åˆå¹¶å¤šæ–‡æ¡£å†…å®¹

### 2. åˆ†æå™¨ (Analyzers)
- **RequirementAnalyzer**: éœ€æ±‚ç†è§£å’Œä»»åŠ¡åˆ†è§£
- **ModelSearcher**: HuggingFaceæ¨¡å‹æœç´¢å’Œæ¨èï¼ˆé›†æˆçˆ¬è™«åŠŸèƒ½ï¼‰
- **DatasetDesigner**: æ•°æ®é›†æ„å»ºæ–¹æ¡ˆè®¾è®¡
- **ExperimentDesigner**: ç½‘æ ¼åŒ–å®éªŒæ–¹æ¡ˆè®¾è®¡
- **ResultAnalyzer**: å®éªŒç»“æœåˆ†æå’Œé€‰å‹å»ºè®®

### 3. æç¤ºè¯ç®¡ç† (PromptManager)
- å†…ç½®ä¸“ä¸šæç¤ºè¯æ¨¡æ¿
- æ”¯æŒè‡ªå®šä¹‰æç¤ºè¯
- å˜é‡åŠ¨æ€æ›¿æ¢

### 4. LLMå®¢æˆ·ç«¯ (LLMClients) ğŸ†•
- **OpenAIClient**: æ”¯æŒOpenAI APIï¼ˆå¦‚GPT-3.5ã€GPT-4ï¼‰
- **DeepSeekClient**: æ”¯æŒDeepSeek APIï¼ˆå¦‚deepseek-chatã€deepseek-reasonerï¼‰
- **BaiLianClient**: æ”¯æŒé˜¿é‡Œäº‘ç™¾ç‚¼APIï¼ˆå¦‚é€šä¹‰åƒé—®ç³»åˆ—æ¨¡å‹ï¼‰
- **å·¥å‚æ¨¡å¼**: å¯é€šè¿‡é…ç½®æ–‡ä»¶è½»æ¾åˆ‡æ¢ä¸åŒæä¾›å•†

### 5. HuggingFaceçˆ¬è™« (Crawler)
- **è‡ªåŠ¨çˆ¬å–æ¨¡å‹ä¿¡æ¯**: æ ¹æ®ä»»åŠ¡ç±»å‹çˆ¬å–TopKä¸ªæ¨¡å‹
- **å¤šç§æ’åºæ–¹å¼**: trending/downloads/likes/created/updated
- **ModelCardæå–**: è‡ªåŠ¨çˆ¬å–å¹¶ä¿å­˜æ¨¡å‹è¯¦ç»†æ–‡æ¡£
- **ä»»åŠ¡ç®¡ç†**: å†…ç½®HuggingFaceæ‰€æœ‰ä»»åŠ¡ç±»å‹é…ç½®
- **å¹¶å‘çˆ¬å–**: æ”¯æŒå¤šçº¿ç¨‹æ‰¹é‡çˆ¬å–

### 6. Papers with Codeçˆ¬è™« (PwCCrawler)
- **çƒ­é—¨è®ºæ–‡çˆ¬å–**: è·å–Papers with Codeé¦–é¡µçƒ­é—¨è®ºæ–‡
- **é¢†åŸŸæœç´¢**: æŒ‰å­¦æœ¯é¢†åŸŸæœç´¢ç›¸å…³è®ºæ–‡
- **å…³é”®è¯æœç´¢**: æ”¯æŒè‡ªå®šä¹‰å…³é”®è¯æœç´¢è®ºæ–‡
- **GitHubä»“åº“æå–**: è‡ªåŠ¨æå–è®ºæ–‡é¡µé¢ä¸­çš„GitHubä»“åº“é“¾æ¥
- **å…ƒæ•°æ®æå–**: æå–è®ºæ–‡æ ‡é¢˜ã€ä½œè€…ã€å‘å¸ƒæ—¥æœŸã€æ‘˜è¦ç­‰ä¿¡æ¯

### 7. GitHubä»“åº“åˆ†æå™¨ (GitHubRepoAnalyzer)
- **ä»“åº“å…‹éš†**: è‡ªåŠ¨å…‹éš†æŒ‡å®šçš„GitHubä»“åº“
- **è¯­è¨€ç»Ÿè®¡**: åˆ†æä»“åº“çš„ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ
- **ä¾èµ–åˆ†æ**: æå–Python/JavaScriptç­‰è¯­è¨€çš„ä¾èµ–ä¿¡æ¯
- **æ–‡ä»¶ç»“æ„åˆ†æ**: åˆ†æä»“åº“çš„æ–‡ä»¶ç»“æ„å’Œå…³é”®æ–‡ä»¶
- **ä»“åº“è¯„ä¼°**: åŸºäºå¤šç»´åº¦æŒ‡æ ‡è¯„ä¼°ä»“åº“è´¨é‡

## ğŸ”§ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡
```bash
# OpenAI
OPENAI_API_KEY      # OpenAI APIå¯†é’¥
OPENAI_BASE_URL     # è‡ªå®šä¹‰APIç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰

# DeepSeek
DEEPSEEK_API_KEY    # DeepSeek APIå¯†é’¥

# é˜¿é‡Œäº‘ç™¾ç‚¼
DASHSCOPE_API_KEY   # ç™¾ç‚¼ APIå¯†é’¥
```

### é…ç½®æ–¹å¼
æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼é…ç½®AutoForgeï¼š

1. **ç¯å¢ƒå˜é‡**ï¼šå¦‚ä¸Šæ‰€ç¤ºè®¾ç½®ç¯å¢ƒå˜é‡
2. **ç›´æ¥æä¾›**ï¼šåœ¨ä»£ç ä¸­ç›´æ¥æä¾›APIå¯†é’¥å’Œé…ç½®å‚æ•°
3. **ç¤ºä¾‹ä»£ç **ï¼šå‚è€ƒexamples/search_models.pyä¸­çš„é…ç½®æ–¹å¼

ç¤ºä¾‹é…ç½®ï¼ˆæ¥è‡ªsearch_models.pyï¼‰ï¼š
```python
# æ¨¡å‹é…ç½®æ˜ å°„
MODEL_CONFIGS = {
    "deepseek-reasoner": {
        "provider": "DeepSeek",
        "api_key": os.getenv("DEEPSEEK_API_KEY", ""),
        "model_name": "deepseek-reasoner",
        "client_class": "DeepSeekClient"
    },
    "qwen-plus": {
        "provider": "é˜¿é‡Œäº‘ç™¾ç‚¼",
        "api_key": os.getenv("BAILIAN_API_KEY", ""),
        "model_name": "qwen-plus", 
        "client_class": "BaiLianClient"
    }
}

# é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹
SELECTED_MODEL = "deepseek-reasoner"  # å¯é€‰: "deepseek-reasoner", "qwen-plus"
```

### Agenté…ç½®
```python
agent = AutoForgeAgent(
    llm_client=llm_client,  # ç›´æ¥æä¾›LLMå®¢æˆ·ç«¯
    llm_config=llm_config,  # æˆ–é€šè¿‡é…ç½®åˆ›å»ºå®¢æˆ·ç«¯
    output_dir="outputs",   # è¾“å‡ºç›®å½•
    custom_prompts_dir=None # è‡ªå®šä¹‰æç¤ºè¯ç›®å½•
)
```

## ğŸ“ è¾“å‡ºç¤ºä¾‹

### éœ€æ±‚åˆ†æç»“æœ
- éœ€æ±‚æ¦‚è¿°
- ç®—æ³•ä»»åŠ¡åˆ†è§£
- è¯„ä¼°æŒ‡æ ‡å®šä¹‰
- æ•°æ®éœ€æ±‚åˆ†æ
- æŠ€æœ¯çº¦æŸ

### æ¨¡å‹æ¨èç»“æœ
- å€™é€‰æ¨¡å‹åˆ—è¡¨
- æ¨¡å‹å¯¹æ¯”åˆ†æ
- æ¨èç†ç”±
- å®æ–½å»ºè®®

### æ•°æ®é›†è®¾è®¡æ–¹æ¡ˆ
- æ•°æ®è§„æ¨¡å»ºè®®
- æ•°æ®æ”¶é›†æ–¹æ¡ˆ
- æ ‡æ³¨æ–¹æ¡ˆè®¾è®¡
- è´¨é‡ä¿è¯æªæ–½

### å®éªŒè®¾è®¡æ–¹æ¡ˆ
- è¶…å‚æ•°ç½‘æ ¼
- å®éªŒæ‰§è¡Œè®¡åˆ’
- ç›‘æ§æŒ‡æ ‡
- æŠ¥å‘Šæ¨¡æ¿

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ã€æå‡ºé—®é¢˜æˆ–å»ºè®®ï¼

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## ğŸ™ è‡´è°¢

- HuggingFace ç¤¾åŒº
- OpenAI
- DeepSeek
- é˜¿é‡Œäº‘ç™¾ç‚¼
- æ‰€æœ‰è´¡çŒ®è€…

---

**æ³¨æ„**: AutoForge ç›®å‰å¤„äºæ´»è·ƒå¼€å‘ä¸­ï¼ŒAPIå¯èƒ½ä¼šæœ‰å˜åŒ–ã€‚å»ºè®®å…³æ³¨é¡¹ç›®æ›´æ–°ï¼

## ğŸ‰ çˆ¬è™«æ¨¡å—å»ºè®¾å®Œæˆï¼

æˆ‘å·²ç»ä¸ºAutoForgeé¡¹ç›®æˆåŠŸå»ºè®¾äº†å®Œæ•´çš„HuggingFaceæ¨¡å‹çˆ¬è™«æ¨¡å—ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦å®ç°å†…å®¹ï¼š

### ğŸ“ æ–°å¢æ–‡ä»¶ç»“æ„

```
<code_block_to_apply_changes_from>
```

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½

1. **ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ**
   - å†…ç½®50+ç§HuggingFaceä»»åŠ¡ç±»å‹
   - æ”¯æŒå¤šç§æ’åºæ–¹å¼ï¼ˆtrending/downloads/likesç­‰ï¼‰
   - YAMLé…ç½®æ–‡ä»¶ç®¡ç†

2. **æ™ºèƒ½çˆ¬è™«**
   - æ”¯æŒçˆ¬å–TopKä¸ªæ¨¡å‹ï¼ˆå¯é…ç½®ï¼‰
   - è‡ªåŠ¨æå–æ¨¡å‹ä¿¡æ¯ï¼ˆIDã€åç§°ã€ä¸‹è½½é‡ã€ç‚¹èµæ•°ç­‰ï¼‰
   - ModelCardè¯¦ç»†å†…å®¹çˆ¬å–
   - å¹¶å‘çˆ¬å–æ”¯æŒ

3. **é¡µé¢è§£æå™¨**
   - é€šç”¨HTMLè§£æå™¨ï¼Œé€‚åº”é¡µé¢å˜åŒ–
   - å¤šç§è§£æç­–ç•¥ï¼Œæé«˜æˆåŠŸç‡

4. **ä¸AutoForgeæ·±åº¦é›†æˆ**
   - ModelSearcherè‡ªåŠ¨è°ƒç”¨çˆ¬è™«
   - çˆ¬å–çš„æ¨¡å‹ä¿¡æ¯å¢å¼ºLLMæ¨è
   - æœ¬åœ°ç¼“å­˜æœºåˆ¶

### ğŸ“ ä½¿ç”¨ç¤ºä¾‹

```python
# 1. ç›´æ¥ä½¿ç”¨çˆ¬è™«
from autoforge.crawler import HuggingFaceCrawler

crawler = HuggingFaceCrawler()
models = crawler.crawl_models_by_task(
    task_tag="text-classification",
    sort="trending",
    top_k=10
)

# 2. é›†æˆåˆ°AutoForgeå·¥ä½œæµ
from autoforge import AutoForgeAgent

agent = AutoForgeAgent(llm_client=llm_client)
result = agent.search_models()  # è‡ªåŠ¨çˆ¬å–ç›¸å…³æ¨¡å‹
```

### âœ… æµ‹è¯•ç»“æœ

è¿è¡Œ `python test_crawler.py` æµ‹è¯•ç»“æœï¼š
- âœ… ä»»åŠ¡ç®¡ç†å™¨ï¼šæˆåŠŸåŠ è½½50ä¸ªä»»åŠ¡ç±»å‹
- âœ… HTMLè§£æå™¨ï¼šè§£æåŠŸèƒ½æ­£å¸¸
- âœ… HuggingFaceçˆ¬è™«ï¼šåˆå§‹åŒ–æˆåŠŸ
- âœ… æ¨¡å‹æœç´¢å™¨é›†æˆï¼šæˆåŠŸè¯†åˆ«ä»»åŠ¡ç±»å‹

### ğŸ”§ é…ç½®é€‰é¡¹

æ”¯æŒçµæ´»é…ç½®ï¼š
- çˆ¬è™«åŸºç¡€URLï¼ˆæ”¯æŒé•œåƒç«™ï¼‰
- å¹¶å‘çº¿ç¨‹æ•°
- è¯·æ±‚å»¶è¿Ÿ
- è¾“å‡ºç›®å½•

### ğŸ“š æ–‡æ¡£

- `README.md` - å·²æ›´æ–°ï¼Œæ·»åŠ çˆ¬è™«åŠŸèƒ½è¯´æ˜
- `CRAWLER_README.md` - çˆ¬è™«æ¨¡å—è¯¦ç»†æ–‡æ¡£
- `requirements.txt` - å·²æ·»åŠ å¿…è¦ä¾èµ–ï¼ˆbeautifulsoup4, requests, pyyamlï¼‰

### ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®

1. è¿è¡Œçˆ¬è™«ç¤ºä¾‹ï¼š`python examples/crawler_demo.py`
2. æµ‹è¯•é›†æˆåŠŸèƒ½ï¼š`python examples/autoforge_with_crawler.py`
3. æ ¹æ®å®é™…HuggingFaceé¡µé¢ç»“æ„è°ƒæ•´è§£æå™¨
4. å®šæœŸæ›´æ–°ä»»åŠ¡ç±»å‹é…ç½®æ–‡ä»¶

çˆ¬è™«æ¨¡å—ç°å·²å®Œå…¨é›†æˆåˆ°AutoForgeé¡¹ç›®ä¸­ï¼Œå¯ä»¥è‡ªåŠ¨è·å–HuggingFaceæœ€æ–°çš„æ¨¡å‹ä¿¡æ¯ï¼Œæå‡æ¨¡å‹æ¨èçš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ï¼

## åŠŸèƒ½ç‰¹æ€§

- ğŸ¤– **æ™ºèƒ½éœ€æ±‚åˆ†æ**: è‡ªåŠ¨è§£ææ–‡æ¡£å’Œéœ€æ±‚æè¿°
- ğŸ” **æ¨¡å‹æœç´¢æ¨è**: åŸºäºHuggingFaceçš„æ™ºèƒ½æ¨¡å‹æ¨è
- ğŸ“Š **æ•°æ®é›†è®¾è®¡**: è‡ªåŠ¨åŒ–æ•°æ®é›†æ„å»ºæ–¹æ¡ˆè®¾è®¡
- ğŸ§ª **å®éªŒè®¾è®¡**: ç½‘æ ¼åŒ–è¶…å‚æ•°å®éªŒè®¾è®¡
- ğŸ“ˆ **ç»“æœåˆ†æ**: æ™ºèƒ½åŒ–å®éªŒç»“æœåˆ†æå’Œå»ºè®®
- ğŸ–¼ï¸ **å¤šæ¨¡æ€æ”¯æŒ**: æ”¯æŒå›¾ç‰‡ã€æ–‡æ¡£ç­‰å¤šç§æ ¼å¼çš„å†…å®¹ç†è§£
- ğŸŒ **å¤šLLMæ”¯æŒ**: æ”¯æŒOpenAIã€DeepSeekã€é˜¿é‡Œäº‘ç™¾ç‚¼ç­‰å¤šç§å¤§æ¨¡å‹

## å¤šæ¨¡æ€åŠŸèƒ½

AutoForgeæ”¯æŒä½¿ç”¨é€šä¹‰åƒé—®å¤šæ¨¡æ€æ¨¡å‹ï¼ˆqwen-vl-plus/qwen-vl-maxï¼‰è¿›è¡Œå›¾ç‰‡å†…å®¹ç†è§£ï¼š

### æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
- JPG/JPEG
- PNG  
- BMP
- GIF
- TIFF

### å›¾ç‰‡åˆ†æèƒ½åŠ›
- ğŸ“ **æ–‡å­—æå–**: è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹
- ğŸ“Š **å›¾è¡¨ç†è§£**: åˆ†æå›¾è¡¨ã€è¡¨æ ¼çš„ç»“æ„å’Œæ•°æ®
- ğŸ”„ **æµç¨‹å›¾è§£æ**: ç†è§£æµç¨‹å›¾ã€æ¶æ„å›¾çš„é€»è¾‘å…³ç³»
- ğŸ¯ **å…³é”®ä¿¡æ¯æå–**: æå–å›¾ç‰‡ä¸­çš„é‡è¦ä¿¡æ¯å’Œç»†èŠ‚

### ä½¿ç”¨ç¤ºä¾‹

```python
from autoforge.llm import BaiLianClient

# åˆå§‹åŒ–å¤šæ¨¡æ€å®¢æˆ·ç«¯
client = BaiLianClient(model="qwen-vl-plus")

# åˆ†æå•å¼ å›¾ç‰‡
result = client.analyze_image(
    image_path="path/to/image.jpg",
    prompt="è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹"
)

# æ‰¹é‡åˆ†æå›¾ç‰‡
results = client.analyze_images_batch(
    image_paths=["img1.jpg", "img2.png"],
    prompt="è¯·æè¿°å›¾ç‰‡å†…å®¹"
)
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# é˜¿é‡Œäº‘ç™¾ç‚¼APIå¯†é’¥ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
DASHSCOPE_API_KEY=your_dashscope_api_key

# æˆ–è€…ä½¿ç”¨å…¶ä»–æ¨¡å‹
DEEPSEEK_API_KEY=your_deepseek_api_key
OPENAI_API_KEY=your_openai_api_key
```

### 3. è¿è¡Œç¤ºä¾‹

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python examples/quick_start.py

# å¤šæ¨¡æ€åŠŸèƒ½æµ‹è¯•
python examples/test_multimodal.py
```

## é¡¹ç›®ç»“æ„

```
autoforge/
â”œâ”€â”€ llm/                    # LLMå®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ bailian_client.py   # ç™¾ç‚¼å®¢æˆ·ç«¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
â”‚   â”œâ”€â”€ deepseek_client.py  # DeepSeekå®¢æˆ·ç«¯
â”‚   â””â”€â”€ openai_client.py    # OpenAIå®¢æˆ·ç«¯
â”œâ”€â”€ docparser/              # æ–‡æ¡£è§£æå™¨
â”‚   â”œâ”€â”€ parser.py           # å¤šæ¨¡æ€æ–‡æ¡£è§£æå™¨
â”‚   â””â”€â”€ converters.py       # æ ¼å¼è½¬æ¢å™¨
â”œâ”€â”€ analyzers/              # åˆ†æå™¨æ¨¡å—
â”œâ”€â”€ crawler/                # HuggingFaceçˆ¬è™«
â””â”€â”€ prompts/                # æç¤ºè¯æ¨¡æ¿
```

## ä½¿ç”¨åœºæ™¯

1. **æ–‡æ¡£ç†è§£**: è‡ªåŠ¨è§£æåŒ…å«å›¾ç‰‡çš„æŠ€æœ¯æ–‡æ¡£ã€éœ€æ±‚æ–‡æ¡£
2. **å›¾è¡¨åˆ†æ**: ç†è§£ä¸šåŠ¡å›¾è¡¨ã€æ•°æ®å¯è§†åŒ–å›¾ç‰‡
3. **æµç¨‹æ¢³ç†**: åˆ†ææµç¨‹å›¾ã€æ¶æ„å›¾ç­‰æŠ€æœ¯å›¾è¡¨
4. **å¤šæ¨¡æ€éœ€æ±‚åˆ†æ**: ç»“åˆæ–‡å­—å’Œå›¾ç‰‡è¿›è¡Œç»¼åˆéœ€æ±‚ç†è§£

## æ³¨æ„äº‹é¡¹

- å¤šæ¨¡æ€åŠŸèƒ½éœ€è¦é…ç½®é˜¿é‡Œäº‘ç™¾ç‚¼APIå¯†é’¥
- å›¾ç‰‡åˆ†æåŠŸèƒ½ä¼šæ¶ˆè€—ç›¸åº”çš„APIè°ƒç”¨æ¬¡æ•°
- å»ºè®®å›¾ç‰‡å¤§å°æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…ä»¥æé«˜å¤„ç†æ•ˆç‡
